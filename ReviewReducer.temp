import java.io.IOException;

import org.apache.hadoop.io.DoubleWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

public class ReviewReducer extends Reducer<Text, DoubleWritable, Text, DoubleWritable> {


    @Override
    public void reduce(Text key, Iterable<DoubleWritable> values, Context context) throws IOException, InterruptedException {
	double sum = 0;
        for (DoubleWritable value : values) {
        	sum += value.get();
	}
	ReviewDataWritable data = new ReviewDataWritable();
	data.setStars(sum);
	context.write(key, new DoubleWritable(sum));
    }
     /*
    @Override
    protected void cleanup(Context context) throws IOException, InterruptedException {
        // Find the business ID with the highest average stars
        double maxStars = Double.MIN_VALUE;
        String maxBusinessId = "";

        for (Text key : context.getCurrentKey()) {
            double stars = context.getCurrentValue().get();
            if (stars > maxStars) {
                maxStars = stars;
                maxBusinessId = key.toString();
            }
        }

        // Emit the business ID with the highest average stars as the final output
        outputKey.set("Business ID with highest average stars");
        outputValue.set(maxStars);
        context.write(outputKey, outputValue);
    }*/

}
